{"title":"A model break-up","description":"Sometimes all your story needs is a better ending.","hed":"A <span>model</span> break-up","dek":"Sometimes all your story needs is a better ending.","author1":"<a href=https://pudding.cool/author/pamela-mishkin/ target=_blank>Pamela Mishkin</a>","author2":"GPT-3","with":"<a href=https://pudding.cool/author/russell-goldenberg/ target=_blank>Russell Goldenberg</a> and <a href=https://pudding.cool/author/jan-diehm/ target=_blank>Jan Diehm</a>","story":[{"prose":[{"type":"text","value":"O* and I matched 13 days before I left England. From that point on, we spent maybe 12 hours apart. The rest was <span class=switch>walking hand in hand down the river Cam, watching the nonchalant punting tourists</span><span>sitting in the grass on the lawn of King's College, laughing our arses off of the Footlights Pantomime.</span><span>fumbling our way through the college bar crawl, cycling to Grantchester for tea and scones.</span> It was the perfect beginning but it happened at the end of the year."},{"type":"text","value":"I needed to leave for a new job in San Francisco. He needed to stay to finish his PhD. I begged the airline to let me change my flight. He sprinted to the train station to say goodbye."},{"type":"text","value":"I always assumed you don’t realize when you’re living in a cliche. But, in actuality, when you’re on one end of the romantic comedy trope, waiting at the station for a person who looks like they <span class=active>could have appeared in an Ezra Pound poem</span>, you recognize and fear the inevitable final scene. Nothing can actually stay trite forever. <span class=active>In real life the ending is never so neat.</span>"}],"decision":[{"leadin":"He said he’d move to be with me.","title":"I canceled my flight.","type":"generation","text":[{"type":"text","value":"But it was too late. <br>He was gone.<br> I didn’t even know his last name."}]},{"leadin":"He said he’d move to be with me.","title":"I got on the plane.","type":"reality","text":[{"type":"text","value":"I ended things. And then, because I am a millennial or because I am me, I tried to change the ending. He would not take me back, but suggested we try being friends."},{"type":"text","value":"I am not a writer, I am a machine learning engineer. In my work the question of whether something is cliche or not, over or not is steeped in data and trendlines: How does it compare to the mode of a distribution? Is the time series stationary? Answering these questions requires poring over every piece of a dataset, extracting features that might mean something, identifying every possible inflection point. When I try to apply this energy to my love life (or lack thereof), friends tell me I’m “dwelling too much on the past” or “living in a fantasy world” or “not really their friend.”"},{"type":"text","value":"So, when two years had passed and my feelings for O still weren’t resolved, I didn’t tell my friends. I told a supercomputer."}]},{"leadin":"He said he’d move to be with me.","title":"He moved with me.","type":"generation","text":[{"type":"text","value":"I moved in.<br> I started my new job.<br> We got engaged.<br> We sold our flat in London.<br> He moved to California.<br> I moved in.<br> We got married.<br> And now, we’re writing a book."}]}]},{"prose":[{"type":"text","value":"GPT-3 — the third “generative pre-trained transformer” released by the start-up (and my employer) OpenAI — is an example of a language model, or a tool that predicts what sequence of words should follow a user-provided prompt. Given a prompt like, “Hello my name” it will, more often than not, suggest that the next word is <span>is</span>."},{"type":"text","value":"It happens to be the biggest publicly released model of its kind: 175 billion parameters. The next largest is 17 billion. You can think of a parameter roughly as a synapse; the human brain has around 100 trillion of those, but it has to focus on lots of things besides language, like swiping on dating apps and moving to San Francisco. To learn all of those parameters, GPT-3 is trained on hundreds of billions of sentences and stories from the internet and books. Written something on Reddit? There’s a good chance GPT-3 has read it."},{"type":"text","value":"This scale results in some remarkable generalizations: while the model has not eaten dumplings on the King’s College lawn, it has “read” Sylvia Plath and Caroline Calloway and every Modern Love essay ever written and it has “learned” heartbreak from Tosca and Taylor Swift and back issues of Sassy. Because the model has read from so many different sources with so many different authors, and also because it is a computer, the model lacks self-awareness. Given a prompt like “Hi, I’m Pamela and O doesn’t love me” it will respond as me, <span class=active>Pamela, and write the story of a relationship with all the poeticism and pathos and, yes, melodrama, that any young woman who has been dumped could ever want</span>."},{"type":"text","value":"I entered different permutations of my story, asking the model questions of what had gone wrong, hoping I could identify variables to land at the ending I wanted, or, I thought, find the variable that was to blame for the ending I had."},{"type":"text","value":"“What if his bike hadn’t been stolen after our second date?”"},{"type":"text","value":"<span class=switch>If O’s bike hadn't been stolen, it would have ended a lot sooner. He wouldn’t have needed to run to the train station.</span><span>I would have stood him up on our third date. Because I was still really raw from the guy I’d dated for the previous two years. I knew all the signs of a commitment phobe. But I was still really into O and I still wanted to get to know him better.</span><span>We would be engaged right now.</span><span>We would be engaged right now.</span>"},{"type":"text","value":"“What if he hadn’t just gotten out of a seven year relationship?”"},{"type":"text","value":"<span class=switch>If he hadn’t just gotten out of a seven year relationship, they almost certainly would have married and had kids.</span><span>He still would have been in a seven-year relationship. We would have broken up, but maybe we would have been friends.</span><span>I might have fallen in love for good.</span>"},{"type":"text","value":"“What if I’d flown back to England on a unicorn made of marshmallows?”"},{"type":"text","value":"<span class=switch>I would have been pretty confused.</span><span>I’d have let the marshmallow unicorn melt.</span><span>I would have been six inches tall and I would have been eaten by a squirrel.</span><span>I would have had some really good Instagram content.</span>"}]},{"prose":[{"type":"text","value":"I first got access to the model in August. It was the fifth month of quarantine and I had recently moved home to face my teenage journals. I didn’t know if I missed talking to strangers or if I missed talking to O. But I wanted to know if, with enough prodding, I could turn GPT-3 into either, or at least convince myself that I had."},{"type":"text","value":"While I knew then that the model is far from a qualified relationship coach or therapist (access for particular uses is governed by strict guidelines). I wanted to probe its capabilities on a task I knew intimately and I wanted to understand how to explain the model's capabilities and weaknesses in language that made sense to those close to me."},{"type":"text","value":"At the same time, the process was a clear example of how my safety and security using this technology is directly linked to my identity as a White woman who was in a straight relationship."},{"type":"text","value":"The generations shown in this essay are cherry-picked to demonstrate particular aspects of the model and what it taught me about my relationship and GPT-3. They're also chosen to minimize the reader's exposure to harmful and toxic content. As one example, GPT-3 tends to take O's name and, because of its Arab origin, spew racist and anti-Muslim rhetoric. Other responses are sexist and misogynistic. GPT-3 is trained on the internet, and it replicates, and potentially magnifies, the toxicity of those forums. This encoded bias can perpetuate real harm when language models are released in the real world."},{"type":"text","value":"To learn more about this harm, as well as OpenAI’s response to it, I recommend the <a href=https://arxiv.org/abs/2005.14165 target=_blank>original GPT-3 paper</a> and <a href=http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf target=_blank>Bender, Gebru et al</a>."}]},{"prose":[{"type":"text","value":"Others test using AI to solve medical mysteries or probe the human psyche. They say this reveals something about how humans learn or the nature of intelligence."},{"type":"text","value":"One argument against the model’s intelligence is that it has a tendency to “overfit.” This happens when the model essentially memorizes the training data and assumes that everything else should look like it."},{"type":"text","value":"You meet someone, you fall in love, you break up, and, heartbroken, you assume you'll never find anyone who compares. You look for a perfect substitute."},{"type":"text","value":"In the context of a language model, \"overfitting\" tends to show up as endless loops of identical language. While models have gotten better at avoiding these traps as they’ve gotten larger, there are still sequences of words and language that trigger this spiraling behavior."},{"type":"text","value":"O and I were stuck in a loop. I would text, he wouldn't respond for a few weeks, and then would call one day to check-in."},{"type":"text","value":"Over the first year after I left Cambridge, we oscillated between chatting multiple times a day and not speaking for weeks. When we did talk, we mostly discussed whomever we were seeing at the time. I was rarely seeing anyone so he did most of the talking."},{"type":"text","value":"Occasionally one of us would say something that crossed whatever friendship boundary lay between us, a shift in tone somehow more relevant than the 5000 miles. I would text, he wouldn't respond for a few weeks, and then would call one day to check-in."},{"type":"text","value":"Despite this, it was casual enough that I was not surprised when he asked if I needed a place to stay on a layover in London. There was anticipation but not expectation when we discussed how his roommates would feel about someone sleeping on the couch."},{"type":"text","value":"Around a week before I was due to arrive he stopped replying to me. Angry and embarrassed, I finally convinced him to meet me at the hotel my sister booked when she saw the writing on the wall. We walked and talked for eight hours and then we made out and then he said, “I finally feel comfortable being your friend.”"},{"type":"text","value":"My friends say to Venmo-request him for the price of the hotel room. They say to delete his number and texts and Facebook messages and not to forget to disconnect on LinkedIn lest I \"accidentally\" congratulate him on a promotion years down the line. They say there’s no intelligence behind my desire to stay friends with him."}],"decision":[{"leadin":"He calls.","title":"I don't answer.","type":"generation","text":[{"type":"text","value":"He texts,<br> I don't respond.<br> He emails,<br> I don't respond.<br> He sends me a Facebook message,<br> I don't respond."},{"type":"text","value":"I don't want to be friends with him.<br> I don't want to be friends with anyone.<br> I want to be alone."},{"type":"text","value":"I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want to be alone<br> and I want"}]},{"leadin":"He calls.","title":"I answer and fall back in.","type":"reality","text":[{"type":"text","value":"When you prompt GPT-3, you request a certain number of words back. A language model is only able to handle a limited number of words in prompt plus generation. This means that it may end your story mid-sentence or thought. Or, it may reach an ending and then keep generating because it’s been instructed to talk for a certain amount of time about the characters it’s been prompted with. If there are two characters in its universe you are forced to engage with them, even after they and you should have moved on."}]},{"leadin":"He calls.","title":"I answer and end it.","type":"generation","text":[{"type":"text","value":"\"I’m sorry,<br> I’m not interested in talking to you,\"<br> I say."},{"type":"text","value":"\"I’m sorry,<br> I’m not interested in talking to you,\"<br> he says."},{"type":"text","value":"\"I’m sorry,<br> I’m not interested in talking to you,\"<br> I say."},{"type":"text","value":"\"I’m sorry,<br> I’m not interested in talking to you,\"<br> he says."},{"type":"text","value":"\"I’m sorry,<br> I’m not interested in talking to you,\"<br> I say."}]}]},{"prose":[{"type":"text","value":"He called one day in the week preceding quarantine and I joked we should meet in New York. He smiled and said, “Actually, that would be pretty fun, I’ll look at flights, let’s talk soon.”"},{"type":"text","value":"By then we were already used to conducting a friendship or relationship or something in between entirely on video chat. We didn’t know the rest of the world soon would be too."},{"type":"text","value":"The next day New York shut down. A couple weeks later he had met someone new on a dating app, “We’re just chatting though.” More months passed."}],"decision":[{"leadin":"He called.","title":"I answer the phone as my friends.","type":"generation","text":[{"type":"<strong>O","value":"</strong><span>“It’s funny, she’s in San Francisco and basically has your dream job.”</span>"},{"type":"text","value":"<strong>My friends: </strong><br>Never contact me again."}]},{"leadin":"He called.","title":"I answer the phone as myself.","type":"reality","text":[{"type":"<strong>O","value":"</strong>“It’s funny, she’s in San Francisco and basically has your dream job.”"},{"type":"<strong>Me","value":"</strong>“Niiiice!”"},{"type":"<strong>O","value":"</strong>“She visited last week and she’s moving to London in January.”"},{"type":"<strong>Me","value":"</strong>“So fun!”"},{"type":"<strong>O","value":"</strong>“Happy to stay friends but know it’s probably weird for you.”"},{"type":"<strong>Me","value":"</strong>“Not at all.\""},{"type":"text","value":"I was upset that he thought my dream job was to manage make-up artists. I was upset that he’d replaced me with someone who lived a few blocks away. I was upset that he probably told her he loved her at the train station. At least that’s what the model said happened."},{"type":"text","value":"Mostly, I was upset that I didn't know if that was his ending it once and for all or if it had really ended months or years prior or if he was going to call me again two weeks down the line just to check in."}]},{"leadin":"He called.","title":"I answer the phone as my teenage self.","type":"generation","text":[{"type":"<strong>O","value":"</strong><span>“It’s funny, she’s in San Francisco and basically has your dream job.”</span>"},{"type":"text","value":"<strong>My teenage self: </strong><br>People who have dreams<br> usually care about stuff<br> that actually happens<br> in the real world."},{"type":"<strong>O","value":"</strong><span>“She visited last week and she’s moving to London in January.”</span>"},{"type":"text","value":"<strong>My teenage self: </strong><br>That’s a long way<br> to go just to avoid<br> seeing someone you hate."}]}]},{"prose":[{"type":"text","value":"When a relationship falls apart slowly, it’s hard to keep track of all the variables — the half-written emails sitting in my drafts folder, the awkward kiss that makes me cringe to this day, the train from London to Cambridge we missed by a few minutes — any of them might have been the end."},{"type":"text","value":"I wanted the model to give me a better ending or maybe just to give me authority over the ending."},{"type":"text","value":"Because the model's data ends in 2019, interacting with it can feel like jumping into a nostalgia machine, just like past relationships look better in the rearview. There's a lot of larger reminiscing that happens around COVID and GPT-3 contextualizes/quantifies just how strange this year is compared to last."},{"type":"text","value":"In GPT-3's endings, sometimes we end up quarantined for COVID-19 together in French Polynesia. Other times he gets the virus and we never see each other again. Sometimes GPT-3 displays the dangers of being trained on the internet, devolving into sexist rants. In many, when I tell GPT-3 that I am mid-pandemic and am using AI to explain my love story I end up falling in love with the AI and running off with it. I suppose there’s a lot of dystopian fan-fiction available as training data."},{"type":"text","value":"<span class=active>On occasion</span> the model’s predicted outcome <span class=active>veered close enough to my truth that there was solace in</span> reading it from a distance. But none of those aching 2020 endings felt as outlandish as his dating someone so familiar. Him, still in London, choosing to spend hours on Facetime with a different woman in the Mission. Some pain is still human."},{"type":"text","value":"I decided if GPT-3 wouldn’t write our ending then I would. <span class=active>Even if I needed some help along the way. </span>"}]}]}