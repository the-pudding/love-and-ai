{"title":"Nothing Breaks Like A.I. Heart","description":"An essay about artificial intelligence, emotional intelligence, and finding an ending","titles":["Love Language Processing","Nothing Breaks Like A.I. Heart","A Model Breakup"],"story":[{"divider":"false","prose":[{"type":"text","value":"Omar and I matched 13 days before I left England. From that point on, we spent maybe 12 hours apart. The rest was <span class=switch>getting lost in the library stacks, walking hand in hand across the Bridge of Sighs.</span><span>sitting in the grass on the lawn of King’s College, laughing our arses off of the Footlights Pantomime.</span><span>fumbling our way through the college bar crawl, cycling to Grantchester for tea and scones.</span> We were filling in the outline of a love story I’d written in my head reading novels and Instagram posts by American women studying abroad.  It was the perfect beginning but it happened at the end of the year."},{"type":"text","value":"I needed to leave for a new job in San Francisco. He needed to stay to finish his PhD. I begged the airline to let me change my flight. He sprinted to the train station to say goodbye."},{"type":"text","value":"<span class=directions>Text that <span class=active>looks like this</span> has been generated and <span class=switch>text with a switch</span><span>text with a toggle</span><span>text with this symbol</span> can be swapped out by clicking.</span>"},{"type":"text","value":"I always assumed you don’t realize when you’re living in a cliche. But, in actuality, when you’re on one end of the romantic comedy trope, waiting at the station for a person who looks like they <span class=switch>could have appeared in an Ezra Pound poem,</span><span>could have appeared in a book about Hemingway’s racing fever,</span><span>could have been at the Chelsea Hotel when Sylvia Plath lived there,</span> you recognize and fear the inevitable final scene. Nothing can actually stay trite forever. <span class=active>In real life the ending is never so neat.</span>"},{"type":"text","value":"<span class=directions>To navigate this story, think of each circle as a chance to choose your own adventure. Pick an <span class=option>option</span> below to change the narrative path.</span>"}],"decision":[{"leadin":"He said he’d move to be with me.","title":"I canceled my flight.","type":"generation","stop":"yes","text":[{"type":"text","value":"I never should’ve fallen <br>for a broke grad student. <br>But I did. <br> And I couldn’t have imagined <br>the nightmare <br>of moving to a new country <br>for him <br>and then getting <br>dumped. <br> A year and a half later, <br>I’m starting to feel <br>like myself again."}]},{"leadin":"He said he’d move to be with me.","title":"I got on the plane.","type":"reality","stop":"no","text":[{"type":"text","value":"He said he’d move to be with me. I got on the plane and ended things. And then, because I am a millennial or because I am me, I tried to change the ending. He wouldn’t take me back, but we agreed to try being friends."}]},{"leadin":"He said he’d move to be with me.","title":"He moved with me.","type":"generation","stop":"yes","text":[{"type":"text","value":"I moved in.<br> I started my new job.<br> We got engaged.<br> We sold our flat in London.<br> He moved to California.<br> I moved in.<br> We got married.<br> And now,<br> we’re writing a book."}]}]},{"divider":"false","prose":[{"type":"text","value":"I am not a writer; I am a machine learning engineer. In my work, the question of whether something has ended or not is steeped in data and trendlines: Is the time series stationary? Is the shock transitory or permanent? Answering these questions requires poring over every piece of a dataset, extracting features that might mean something, identifying each possible inflection point. When I try to apply this energy to my love life (or lack thereof), friends tell me I’m “dwelling too much on the past” or “living in a fantasy world” or “not really their friend.”"},{"type":"text","value":"So, when two years had passed and my feelings for Omar still weren’t resolved, I didn’t tell my friends. I told a supercomputer."}]},{"divider":"true","prose":[{"type":"text","value":"<a href=https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html target=_blank>GPT-3</a> — the third “generative pre-trained transformer” released by the start-up (and my employer) <a href=https://openai.com/blog/openai-api/ target=_blank>OpenAI</a> — is an example of a language model, or a tool that predicts what sequence of words should follow a user-provided prompt. Given a prompt like, “Hello my name” the model will, more often than not, suggest that the next word is <span class=active>is</span>."},{"type":"text","value":"It happens to be the biggest publicly released model of its kind: 175 billion parameters (although access is gated through an API with strict use case guidelines). You can think of a parameter roughly as a synapse; the human brain has around 100 trillion of those, but it has to focus on lots of things besides language, like swiping on dating apps and moving to San Francisco. To learn all of those parameters, GPT-3 is trained on hundreds of billions of sentences and stories from the Internet and books. Written something on Reddit? There’s a good chance GPT-3 has read it."},{"type":"text","value":"<span class=directions>The model learns the toxicity of these forums. The generations shown in this essay are cherry-picked to demonstrate particular aspects of the model and what it taught me about my relationship and GPT-3. They're also chosen to minimize the reader's exposure to harmful and toxic content. Encoded biases in language models perpetuate real harm when language models are released in the real world. To learn more about these and other dangers of big language models, I recommend <a href=http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf target=_blank>Bender, Gebru et. al.</a> and <a href=https://arxiv.org/pdf/2005.14165.pdf target=_blank>the original GPT-3 paper</a>. Access to the model is governed by strict usage guidelines and a content filter is available, but there is, as always, work to do.</span>"},{"type":"text","value":"Because it has read from so many different sources with so many different authors, and also because it is a computer, the model lacks self-awareness. So, given a prompt like, “Hi, I’m Pamela and Omar doesn’t love me.” GPT-3 will respond as me, <span class=active>Pamela, and write the story of a relationship with all the poeticism and pathos and, yes, melodrama, that any young woman who has been dumped could ever want.<span>"},{"type":"text","value":"And, that’s just what I asked for."}],"decision":[{"leadin":"Write","title":"answers to these questions.","type":"generation","stop":"yes","text":[{"type":"text","value":"<span class=flip>What if his bike hadn’t been stolen after our second date?</span>"},{"type":"text","value":"If Omar’s bike <br>hadn’t been stolen, <br>it would have ended <br>a lot sooner. <br>He wouldn’t have needed to run <br>to the train station."},{"type":"text","value":"<span class=flip>What if he hadn’t just gotten out of a seven year relationship?</span>"},{"type":"text","value":"I might have fallen <br>in love <br>for good."},{"type":"text","value":"<span class=flip>What if I’d flown back to England on a unicorn made of marshmallows?</span>"},{"type":"text","value":"I would have had <br>some really good <br>Instagram content."}]},{"leadin":"Write","title":"this story.","type":"reality","stop":"no","text":[{"type":"text","value":"By the time I got access to the model, it was late July. In the fifth month of quarantine, having recently moved home to face my teenage journals, I wasn’t sure if I missed talking to strangers or to Omar.  But I wanted to know if, with enough prodding, I could turn GPT-3 into either, or at least convince myself that I had."},{"type":"text","value":"I put my Notes app drafts into the model hoping to fill in my trailing thoughts. I wrote different permutations thinking I could identify what went wrong. I asked for custom pop songs and sea shanties in the style of <a href=https://en.wikipedia.org/wiki/Tosca target=_blank>Tosca</a> and <a href=https://www.youtube.com/watch?v=aXzVF3XeS8M target=_blank>Taylor Swift</a> about my specific woe. It was as much escapism as it was reining control over a model that can seem incomprehensible and a story that felt no longer mine."}]},{"leadin":"Write","title":"songs about this romance.","type":"generation","stop":"yes","text":[{"type":"text","value":"I heard you were <br>a computer scientist<br> and so I said to myself<br> I’d better get to know her<br> (get to know her)<br> I’d better get to know her<br> (get to know her)"}]}]},{"divider":"pad","prose":[{"type":"text","value":"Others test using AI to answer philosophical questions or probe the psyche. They say this reveals something about how humans learn and the nature of intelligence."},{"type":"text","value":"One argument against the model’s intelligence is that it has a tendency to “overfit,” or get lost in endless loops of repetitive language. This happens when the model essentially memorizes its training data and assumes that everything else should look like it."},{"type":"text","value":"You meet someone, you fall in love, you break up, and, heartbroken, you assume you’ll never find anyone who compares. You look for a perfect substitute."},{"type":"text","value":"While models have gotten better at avoiding these traps as they’ve gotten larger, there are still sequences of words and language that trigger this spiraling behavior."}],"decision":[{"leadin":"I would text.","title":"He would text.","type":"generation","stop":"no","text":[{"type":"text","value":"I would text. He would text. <br> I would call. He would call. <br> I would cry. He would cry. <br> I would say I was sorry.<br> He would say he was sorry."}]},{"leadin":"I would text.","title":"He wouldn’t respond.","type":"reality","stop":"no","text":[{"type":"text","value":"Omar and I were stuck in a loop. I would text, he wouldn’t respond for a few weeks, and then would call one day to check in."}]},{"leadin":"I would text.","title":"He would ignore.","type":"generation","stop":"no","text":[{"type":"text","value":"I would text again.<br> He would ignore again.<br> I would text again.<br> He would ignore again.<br> I would<br> text again.<br> He would<br> ignore again.<br>I <br> would<br> text"}]}]},{"divider":"false","animation":"<div class=left></div><div class=right></div>","prose":[{"type":"text","value":"I tell GPT-3 this and get back, <span class=switch>He says he’s sorry. He says he’s not sorry. He says he’s sorry. He says he’s not sorry. He says he’s…</span><span>He called. I didn’t answer. I called. He didn’t answer. I texted. He didn’t respond. I called. He didn’t answer. I texted. He didn’t respond. I called. He didn’t answer.</span><span>I cry when I think about how much I wanted to be with him. I was so lonely. I was so sad. I was so desperate. I was so stupid. I was so stupid. I was so stupid. I was so stupid.</span> GPT-3’s loops feel reminiscent of picking petals on the schoolyard, \"He loves me. He loves me not. He loves me. He loves me not.\" Loops can be exhausting."},{"type":"text","value":"Occasionally one of us would say something – “you look nice,” “he doesn’t sound like your type,” “her?” – that crossed whatever friendship boundary lay between us, a shift in tone somehow more relevant than the 5,000 miles. I would text, he wouldn’t respond for a few weeks, and then would call one day to tell me about someone new he’d met."},{"type":"text","value":"I learn that in the <a href=https://en.wikipedia.org/wiki/He_loves_me..._he_loves_me_not target=_blank>original French version</a> of the schoolyard petal rhyme you don’t just loop through \"He loves me. He loves me not.\" but question how far the other person’s affection goes: un peu, beaucoup, passionnément, à la folie, pas du tout."},{"type":"text","value":"He loves me a little. He loves me a lot. He loves me passionately. He loves me to madness. He loves me not at all."},{"type":"text","value":"I would text, he wouldn’t respond for a few weeks, and then would call one day to tell me about his recent break-up."}]},{"divider":"true","prose":[{"type":"text","value":"When you prompt GPT-3, you request a certain number of words back. A language model is only able to handle a limited number of words in prompt plus generation. This means that it may end your story mid-sentence or thought. Or, it may reach an ending and then keep generating because it’s been instructed to talk for a certain amount of time about the characters with which it’s been prompted. If there are two characters in its universe you are forced to engage with them, even after they and you should have moved on."},{"type":"text","value":"Despite our awkwardness, it was casual enough that I was not surprised when, a year after I’d left England, he asked if I needed a place to stay on a layover in London. There was anticipation but not expectation when we discussed how his roommates would feel about someone sleeping on the couch."}],"decision":[{"leadin":"Around a week before I was due to arrive he...","title":"suggested we get back together.","type":"generation","stop":"no","text":[{"type":"text","value":"I never<br> thought I’d say this but<br> I was pretty sure<br> I was not ready for that.<br> I said I’d think about it.<br> And then, a week later,<br> I was in the underground,<br> staring at his name on my phone,<br> telling him I’d like to<br> meet for a drink."},{"type":"text","value":"I spent the day in London<br> in a state of disbelief.<br> We both knew<br> there was a line<br> neither of us were going<br> to cross<br> but the possibility<br> of a friendship<br> was real."}]},{"leadin":"Around a week before I was due to arrive he...","title":"stopped replying to me.","type":"reality","stop":"no","text":[{"type":"text","value":"Around a week before I was due to arrive he stopped replying to me. I stared at my phone over four days in Poland. Paid for premium data in Lithuania just in case the replies weren’t coming through. Arrived in London at 5am and schlepped my bag to Cambridge, then back to London and through two museums before my sister told me she’d booked a hotel. I was angry but mostly just embarrassed."},{"type":"text","value":"He texted back, “Sup?”"}]},{"leadin":"Around a week before I was due to arrive he...","title":"told me he was seeing someone new.","type":"generation","stop":"no","text":[{"type":"text","value":"It was a relief to know<br> a breakup was in the cards.<br> There was no need<br> to write a speech<br> or hide my feelings.<br> It was clear<br> he didn’t want<br> to be with me<br> and I didn’t want<br> to be with him.<br> It was also clear<br> that he still wanted<br> to be my friend."}]}]},{"divider":"false","prose":[{"type":"text","value":"I wore my casual cool girl outfit and carried my favorite dress in case we changed plans. We walked and talked for eight hours, <span class=switch>past the Bank of England, past Combe’s Music Hall, past all the Important Historical Places, through and on to a row of houses across from Westminster Bridge</span><span>through the square where the weirdos live and a coffee shop that is starting to feel a lot like a Starbucks, past the door that was featured on a scene in Pride and Prejudice, then down a street where Mary Shelley wrote Frankenstein</span><span>through the City of London and all those tall buildings with the funny names: The Gherkin, The Walkie-Talkie, The Cheesegrater, The Shard, The Spire, The Heron Tower, The Monument, The Axe, The Lloyd's Building, The Leadenhall Building</span> and then we made out and then he said, “I finally feel comfortable being your friend.”"},{"type":"text","value":"My friends say to Venmo-request him for the price of the hotel room and the dress that blew away. My friends say to delete his number and texts and Facebook messages and not to forget to disconnect on LinkedIn lest I \"accidentally\" congratulate him on a promotion years down the line. My friends say there’s no intelligence behind my desire to stay friends with him."}]},{"divider":"true","prose":[{"type":"text","value":"GPT-3 doesn’t care about my friends. It doesn’t care that I work at a start-up, live in a city, that I am quarantined in a house with two other people. <span class=active>It doesn’t care that Omar and I didn’t have the language to say what we wanted from each other, that we fought about his insecurity and my loneliness, that I felt like I was losing myself.</span> It doesn’t care which of my sentences are tired or stale or cliche."},{"type":"text","value":"After all, in a sense everything GPT-3 generates is cliche because it’s all rooted in everything that has been written before. In my experience, the model can struggle to land at something that feels like the truth when a story is more nuanced than boy meets girl, boy and girl break-up, girl is devastated."},{"type":"text","value":"As I write, I notice peculiarities in my sentences: they are circular, they get distracted, they repeat similar phrases. I’m unsure if GPT-3 is picking up on my style or if my writing is adopting the quirks of the model. I'm unsure if GPT-3 is really leading me down its tunneled tropes or if I've also been trained on the same inputs. I’m unsure if it’s true when GPT-3 says it has or hasn’t ended."}]},{"divider":"false","animation":"<div class=train></div>","prose":[{"type":"text","value":"He called one day in the week preceding quarantine and I joked we should meet in New York. He smiled and said, “Actually, that would be pretty fun, I’ll look at flights, let’s talk soon.”"},{"type":"text","value":"The next day New York shut down."},{"type":"text","value":"We chatted, about <span class=switch>the weather and the government and the wealth gap.</span><span>YouTube stars and the transgression of politics and the on-going demise of the human mind.</span><span>Corbyn, and phobias, and love and hate.</span>"},{"type":"text","value":"A month passed. We laughed about the Club Penguin date I’d gone on and his debate about an ex who’d returned to London."},{"type":"text","value":"More months passed. He called."}],"decision":[{"leadin":"I answer the phone as","title":"my friends.","type":"generation","stop":"yes","text":[{"type":"text","value":"<span class=flip><strong>Omar\\: </strong>“It’s funny, she’s in San Francisco and basically has your dream job.”</span>"},{"type":"text","value":"<span class=flip><strong>Me, as my friends\\: </strong><span> <br>Never contact me again."}]},{"leadin":"I answer the phone as","title":"myself.","type":"reality","stop":"no","text":[{"type":"text","value":"<strong>Omar\\: </strong>“It’s funny, she’s in San Francisco and basically has your dream job.”"},{"type":"text","value":"<strong>Me\\: </strong>“Niiiice!”"},{"type":"text","value":"<strong>Omar\\: </strong>“She visited last week and she’s moving to London in January.”"},{"type":"text","value":"<strong>Me\\: </strong>“So fun!”"},{"type":"text","value":"<strong>Omar\\: </strong>“Happy to stay friends but know it’s probably weird for you.”"},{"type":"text","value":"<strong>Me\\: </strong>“Not at all.\""}]},{"leadin":"I answer the phone as","title":"my teenage self.","type":"generation","stop":"yes","text":[{"type":"text","value":"<span class=flip><strong>Omar\\: </strong>“It’s funny, she’s in San Francisco and basically has your dream job.”</span>"},{"type":"text","value":"<span class=flip><strong>Me, as my teenage self\\: </strong></span><br>People who have dreams<br> usually care about stuff<br> that actually happens<br> in the real world."},{"type":"text","value":"<span class=flip><strong>Omar\\: </strong>“She visited last week and she’s moving to London in January.”</span>"},{"type":"text","value":"<span class=flip><strong>Me, as my teenage self\\: </strong></span><br>That’s a long way<br> to go just to avoid<br> seeing someone you hate."}]}]},{"divider":"pad","prose":[{"type":"text","value":"GPT-3’s outputs say I’m upset that he thought my dream job was to manage make-up artists. That I’m upset that he’d replaced me with someone who lived a few blocks away. That I’m upset that he probably told her he loved her at the train station."},{"type":"text","value":"I was mostly upset that I didn’t know if that was his ending it once and for all or if it had really ended months or years prior or if he was going to call me again two days or six months down the line just to check-in."}]},{"divider":"false","prose":[{"type":"text","value":"Contrary to what the model says, I wasn’t devastated that the fairytale didn’t come true."},{"type":"text","value":"The reality is more complicated: we were never really dating so we never really broke up, but we were never really friends so I didn't get to be mad when he ghosted. When a relationship falls apart slowly, it’s hard to keep track of all the variables — the unfinished pack of chocolate stars, the awkward kiss that makes me cringe to this day, the train we missed by a few minutes — any of them might have been the end."},{"type":"text","value":"<span class=active>The reality is less romantic: a man tells a woman he doesn’t want to be with her after spending years looking for his “soul mate,” and then</span> meets someone <span class=active>soon afterwards. She doesn’t tell her friends for a few months, gets her heart broken quietly into pieces while believing she is slowly piecing it back together, then tells everyone at once that it doesn’t matter anymore.</span>"},{"type":"text","value":"<span class=active>On occasion</span> the model’s predicted outcomes <span class=active>veered close enough to my truth that there was solace in</span> reading them from a distance. But, ultimately, they still weren’t true."},{"type":"text","value":"I decided if Omar refused to write an ending and I didn’t agree with how GPT-3 filled it in, then I would write my own. <span class=active>Even if I needed some help along the way.</span>"}]}],"method":[{"type":"text","value":"We used either the base 175B parameter model or a version fine-tuned on “instruction following” for all GPT-3 generations."},{"type":"text","value":"Prompts took two main forms. In some, we did an open-ended generation where we’d prompt the model with a few paragraphs of text and let it do the rest. This is how the “wheel generations” work. In many cases this was with the “story text” that appears above that particular wheel as you read it, however we have made some line-edits since."},{"type":"text","value":"In other cases, mostly where you see rotating \"mad-libs\" options of text, we would prompt the model with a “headline” like \"Lists of classic Cambridge activities,\" followed by samples that fit the flow of text and were examples of what we’d want. This is called <a href=https://medium.com/quick-code/understanding-few-shot-learning-in-machine-learning-bede251a0f67 target=_blank>few-shot learning</a>, we give the model a few samples of what we’re looking for and let GPT-3 do the rest."},{"type":"text","value":"We tried our best not to shoehorn responses. For example, I wanted to place a reference to <a href=https://www.youtube.com/watch?v=Ic5vxw3eijY target=_blank>Estelle’s “American Boy”</a> in one spot but couldn’t get the model to cooperate. Other times cooperation felt like cheating, e.g. putting <a href=https://www.imdb.com/title/tt0128853/ target=_blank><em>You’ve Got Mail</em></a> in the prompt gets <a href=https://www.imdb.com/title/tt0108160/ target=_blank><em>Sleepless in Seattle</em></a> in return."},{"type":"text","value":"For the overfitting section we deliberately lowered the temperature to induce looping behavior from the model. Other generations were done with a temperature between 0.7 and 0.9."}],"notes":[{"type":"text","value":"It’s easy to say I should cite everywhere the model is used but doing so doesn’t fully cover the ways the model influenced the shape and sound of how I wrote this piece."},{"type":"text","value":"Whether or not you are copying precise outputs, it’s easy for a story to take on the shape of the model. When generations don’t look how I’d expect I start to edit out details and nuance in the prompt until the model realizes, “Oh, he had to run to the train station because his bike was stolen.” As noted above, my writing starts to sound like GPT-3: I repeat similar phrases, lose focus in the middle of sentences, and fall back on cliched tropes that feel close enough to the truth. Over time and drafts, the inputs and outputs converge."},{"type":"text","value":"I say all this precisely to get off the hook for what is written here. The process is fun (\"Rewrite this story as Tosca and Taylor Swift and Tolstoy\"), until it’s time to hit publish and Omar tells me he can’t wait to learn the truth from what I write and GPT-3 tells me my writing sounds like a <span>young woman</span> or a <span>teen magazine</span> (which are labels I should not scoff at, but do, but hopefully only because of what I know of the model’s internalized misogyny)."},{"type":"text","value":"Writing with GPT-3, it is hard not to drown in the power of suggestion, “Oh that is a really good framing,” and lose sight of the truth, “No, I really wanted to just be friends!” Even if you feel that truth deeply. It’s similar to writing with an editor, albeit one far less compassionate and patient than Jan is. And so, I write an Author’s Note, just to clarify."}]}