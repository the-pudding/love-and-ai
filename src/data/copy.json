{"hed":"Love and AI","story":[{"prose":[{"alignment":"left","text":"When two years had passed and my feelings for Omar still weren’t resolved, I didn’t tell my friends. I told a supercomputer."},{"alignment":"right","text":"GPT-3 -- the third “generative pre-trained transformer” released by the start-up (and my employer) OpenAI -- is an example of a language model, or a tool that predicts what sequence of words should follow a user-provided prompt. For example, given a prompt like, “Hello my name” it will, more often than not, suggest that the next word is <span class=generation>is</span>."},{"alignment":"right","text":"GPT-3 is the biggest publicly released model of its kind: 175 billion parameters. The next largest is 17 billion. You can think of a parameter roughly as a synapse; the human brain has around 100 trillion of those, but it has to focus on lots of things besides language, like swiping on dating apps and moving to San Francisco. To learn all of those parameters, GPT-3 is trained on hundreds of billions of sentences and stories from the Internet and books. Written something on Reddit? There’s a good chance GPT-3 has read it."},{"alignment":"left","text":"Omar and I matched 13 days before I left England. From that point on, we spent maybe 12 hours apart. The rest was <span class=generation>walking hand in hand down the river Cam, watching the nonchalant punting tourists</span>. I was filling in the outline of a love affair I’d drawn in my head reading novels and Instagram posts written by other women while they studied abroad at Cambridge."},{"alignment":"left","text":"Eventually I needed to leave for a new job in San Francisco. He needed to stay to finish his PhD. I begged the airline to let me change my flight. He sprinted to the train station to say goodbye."}],"decision":[{"hed":"Tk hed 1","text":"Tk text 1"},{"hed":"Tk hed 2","text":"Tk text 2"},{"hed":"Tk hed 3","text":"Tk text 3"}]},{"prose":[{"alignment":"left","text":"I always assumed you don’t realize when you’re living in a cliche. But, in actuality, when you’re  on one end of <span class=generation>[pull from list of movies where this trope is featured]</span>, waiting at the station for a person who just so happens to look like they <span class=generation>could have appeared in an Ezra Pound poem</span>, you recognize and fear the inevitable final scene."},{"alignment":"left","text":"So, when he said he’d move to be with me, I ended things. Months and weeks and days later, I changed my mind. He would not take me back but agreed to try being friends."},{"alignment":"left","text":"Nothing can actually stay trite forever. <span class=generation>In real life the ending is never so neat.</span>"},{"alignment":"right","text":"While GPT-3 has not eaten dumplings on the King’s College lawn, it has “read” Sylvia Plath and Caroline Calloway and every Modern Love essay ever written and it has “learned” heartbreak from Tosca and Taylor Swift and the DSM-V. Because it has read from so many different sources with so many different authors, and also because it is a computer, GPT-3 lacks self-awareness, so, given a prompt like “Hi, I’m Pamela and Omar doesn’t love me” it will respond as me, Pamela, and <span class=generation>write the story of a relationship with all the poeticism and pathos and, yes, melodrama that any young woman who has been dumped could ever want</span>."},{"alignment":"right","text":"So, that’s what I did. I entered every permutation of the relationship I could think of into the model, hoping I could change individual variables until I got the ending I wanted, or, I thought, find the variable that was to blame for the ending I had."}],"decision":[{"hed":"Tk hed 1","text":"Tk text 1"},{"hed":"Tk hed 2","text":"Tk text 2"},{"hed":"Tk hed 3","text":"Tk text 3"}]},{"prose":[{"alignment":"right","text":"One argument against the model’s intelligence is that it has a tendency to “overfit” and end up in repetitive sequences of language. While models have gotten better at avoiding these traps as they’ve gotten larger, there are still sequences of words and language that will trigger this sort of behavior."},{"alignment":"left","text":"Around a year after I left Cambridge, Omar and I had reached a place of chatting every few weeks, mostly about whomever we were seeing at the time. I was rarely seeing anyone so he did most of the talking. My friends would say not to text again, but I would, and we would wind up back on the phone for a few hours."},{"alignment":"left","text":"It was casual enough that I was not surprised when he invited me to stay with him in London on a layover. There was anticipation but not expectation when we discussed how his roommates would feel about someone staying on the couch."}],"decision":[{"hed":"Tk hed 1","text":"Tk text 1"},{"hed":"Tk hed 2","text":"Tk text 2"},{"hed":"Tk hed 3","text":"Tk text 3"}]},{"prose":[{"alignment":"left","text":"Around a week before I was due to arrive he stopped replying. Angry and embarrassed, I finally convinced him to meet me at the hotel my sister booked when she saw the writing on the walls. We walked and talked for eight hours and then we made out and then he said, “I finally feel comfortable being your friend.”"},{"alignment":"right","text":"When I tell that story to friends they are appalled. They say to Venmo-request him for the price of the hotel room. They say to delete his number and texts and Facebook messages and not to forget the call history I might be able to use to get his number after I do all the other things. They say there’s no intelligence behind my desire to stay friends with him."},{"alignment":"right","text":"The model doesn’t care about my friends. It doesn’t care that I work at a start-up, live in a city, that I am quarantined in a house with two other people, that I have been in love, that I have had a breakup. <span class=generation>It doesn’t care that Omar and I didn’t have the language to say what we wanted from each other, that we fought about his insecurity and my loneliness, that I felt like I was losing myself.</span> It doesn’t care which of my sentences are tired or stale or cliche."},{"alignment":"left","text":"I suppose Omar doesn’t care about these things either."}],"decision":[{"hed":"Tk hed 1","text":"Tk text 1"},{"hed":"Tk hed 2","text":"Tk text 2"},{"hed":"Tk hed 3","text":"Tk text 3"}]},{"prose":[{"alignment":"right","text":"When you prompt the AI model, you request a certain number of words back. A language model is only able to handle a limited number of words in its generation. This means that it may end your story mid-sentence or thought. Or, it may reach an ending and then keep generating, because it’s been instructed to talk for a certain amount of time about the characters it’s been prompted with, so if there are two characters in its universe you are forced to engage with them, even after they and you should have moved on."},{"alignment":"left","text":"He called one day at the start of quarantine and I joked he should meet me in New York, he smiled and said, “Actually, that would be pretty fun, I’ll look at flights, let’s talk soon.”"},{"alignment":"left","text":"The next day New York shut down. Months later he met someone new on a dating app, “We’re just chatting though.” Two months passed and he called me."}]},{"prose":[{"alignment":"left","text":"“It’s funny, she’s in San Francisco and basically has your dream job.”"}]}]}